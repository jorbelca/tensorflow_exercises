<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.0.0/dist/tf.min.js"></script>
    <title>Capstone Project</title>
    <link rel="stylesheet" href="styles.css" />
    <script type="module">
      import { createDataObject } from "./generateData.js";
      import { makeModel } from "./trainModel.js";
      import { dicify } from "./inference.js";

      // Exponer funciones usadas por manejadores inline en el HTML
      window.createDataObject = createDataObject;
      window.dicify = dicify;
      window.makeModel = makeModel;

      // Nuevo: envoltorio para gestionar UI durante la inferencia
      window.runInference = async function runInference() {
        const btn = document.getElementById("runBtn");

        try {
          btn.disabled = true;

          await dicify();
        } finally {
          btn.disabled = false;
        }
      };

      // Accesibilidad y mejoras de usabilidad
      const logsHeader = document.getElementById("logs-header");
      const logsContent = document.getElementById("logs-content");
      logsHeader.addEventListener("click", () => {
        const expanded = logsHeader.getAttribute("aria-expanded") === "true";
        logsHeader.setAttribute("aria-expanded", String(!expanded));
        logsContent.hidden = expanded;
      });

      // Carga de imagen de prueba con previsualización
      document.getElementById("imageInput")?.addEventListener("change", (e) => {
        const file = (e.target.files || [])[0];
        if (file) {
          const url = URL.createObjectURL(file);
          const img = document.getElementById("image");
          img.src = url;
          document.getElementById("imageInputName").textContent = file.name;
        }
      });
    </script>
  </head>
  <body>
    <div class="container">
      <div>
        <h1>Capstone Project: Dice Classifier (TensorFlow.js)</h1>
        <p class="explain">
          This demo trains and evaluates a lightweight dice face classifier
          entirely in your browser using TensorFlow.js—no server, no data leaves
          your device.
        </p>
        <p class="explain">
          Workflow: (1) Generate synthetic training data (12×12 grayscale
          patches of dice with high‑contrast pips) or upload a JSON dataset. (2)
          Train a compact CNN and save it locally. (3) Load a test image and run
          inference to label each cell in a grid as a face from 1 to 9.
        </p>
        <p class="explain">
          Under the hood, the app slices the input image into an N×N grid,
          converts each tile to grayscale, optionally binarizes and auto‑inverts
          per tile to match the training distribution, crops a few pixels to
          avoid grid borders, resizes to 12×12, and feeds the batch to the
          model. The canvas then visualizes the per‑tile predictions.
        </p>
        <p class="explain">
          Tip: For best results, use high‑contrast images where dice cells are
          aligned to a uniform grid. All computations run on WebGL/CPU via TFJS
          for fast, private, and portable execution.
        </p>
      </div>

      <div class="section data">
        Training Data
        <p class="explain">
          Generate training data from dice rolls and save as JSON file.
        </p>
        <button class="btn btn-secondary" onclick="createDataObject();">
          Generate Training Data
        </button>
      </div>
      <div class="section data">
        <span>Upload Training Data</span>
        <p class="explain">
          Upload a previously generated JSON file with training data to train
          the model.
        </p>
        <input type="file" id="fileInput" accept=".json" />
        <br />
        <button class="btn btn-secondary" onclick="makeModel();">
          Train Model
        </button>
        <p class="explain">
          Training may take a few minutes depending on the data size and your
          device. The download will include two files: a <u>JSON</u> file with
          the model architecture and a binary file <u>(.bin)</u>with the model
          weights. Please, create a folder to store them together.
        </p>
        <div id="logs-container">
          <button
            id="logs-header"
            class="btn btn-toggle"
            type="button"
            aria-expanded="false"
            aria-controls="logs-content"
          >
            Logs (Click to Expand/Collapse)
          </button>
          <div id="logs-content" hidden>
            <p id="logs" aria-live="polite"></p>
          </div>
        </div>
      </div>

      <div class="section model">
        Model (*.json)

        <input
          id="model_path"
          type="file"
          multiple
          accept=".json,.bin,.weights.bin"
        />
        <p class="explain">
          Upload a trained model (JSON) to run inference on a test image.
        </p>

        <div>
          <p style="margin: 0">Image</p>
          <p class="explain" style="margin: 0">
            The image has to be a black & white image with white background
          </p>
          <input type="file" id="imageInput" accept="image/*" />
          <small id="imageInputName" class="file-name"></small>
        </div>

        <div class="media-grid">
          <img
            id="image"
            src="./imgs/logo.png"
            width="140"
            height="140"
            alt="Imagen de entrada"
          />
          <canvas
            id="display"
            style="image-rendering: pixelated; width: 150px; height: 150px"
            ;
          ></canvas>
        </div>

        <div style="margin-top: 8px">
          <button id="runBtn" class="btn" onclick="runInference();">Run</button>
        </div>
      </div>
    </div>
  </body>
</html>
